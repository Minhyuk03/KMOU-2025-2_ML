{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1a8B86f8bt9ZAFudpjW5MB8fZsjGY4s7L",
      "authorship_tag": "ABX9TyNvCLP1u53ZIxSi5GbTkYaT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minhyuk03/KMOU_2-2_ML/blob/main/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5_%EA%B3%BC%EC%A0%9C_%EC%9D%B4%EB%AF%B8%EC%A7%80_%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPjivgJd41Pk",
        "outputId": "e6528b02-8a6a-4ac6-ab8c-dfdb869f1166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 2000개의 이미지 로드 완료.\n",
            "데이터 크기 (X): (2000, 49152), 레이블 크기 (Y): (2000,)\n",
            "학습 데이터 개수: 1600, 테스트 데이터 개수: 400\n",
            "\n",
            "\n",
            "SVM 모델 학습 및 성능 분석\n",
            "SVM 혼동 행렬 (Confusion Matrix):\n",
            "   [Cat(0) 예측] [Dog(1) 예측]\n",
            "Cat(0) 실제: [182  18]\n",
            "Dog(1) 실제: [ 20 180]\n",
            "정확도 (Accuracy): 0.9050\n",
            "정밀도 (Precision): 0.9091\n",
            "재현율 (Recall): 0.9000\n",
            "F1-Score: 0.9045\n"
          ]
        }
      ],
      "source": [
        "# 1. 필요한 라이브러리 임포트\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "from PIL import Image, ImageEnhance\n",
        "\n",
        "# 2. 이미지 데이터 경로 및 기본 설정\n",
        "BASE_DIR = '/content/drive/MyDrive/test_image/'\n",
        "CLASSES = ['cat', 'dog']\n",
        "IMG_SIZE = (128, 128)\n",
        "USE_COLOR = True\n",
        "USE_AUGMENTATION = True\n",
        "\n",
        "# 3. 데이터 증강 함수 정의\n",
        "def augment_image(img):\n",
        "    \"\"\"이미지 증강: 밝기, 대비, 좌우 반전\"\"\"\n",
        "    augmented_images = [img]\n",
        "\n",
        "    # 좌우 반전\n",
        "    augmented_images.append(img.transpose(Image.FLIP_LEFT_RIGHT))\n",
        "\n",
        "    # 밝기 조정\n",
        "    enhancer = ImageEnhance.Brightness(img)\n",
        "    augmented_images.append(enhancer.enhance(1.2))\n",
        "    augmented_images.append(enhancer.enhance(0.8))\n",
        "\n",
        "    # 대비 조정\n",
        "    enhancer = ImageEnhance.Contrast(img)\n",
        "    augmented_images.append(enhancer.enhance(1.3))\n",
        "\n",
        "    return augmented_images\n",
        "\n",
        "# 4. 데이터 로드 및 전처리 함수 정의\n",
        "def load_and_preprocess_data(base_dir, classes, img_size, use_color=True, use_augmentation=False):\n",
        "    data_X = []\n",
        "    data_Y = []\n",
        "\n",
        "    label_map = {cls: i for i, cls in enumerate(classes)}\n",
        "    file_list = os.listdir(base_dir)\n",
        "\n",
        "    for filename in file_list:\n",
        "        class_name = None\n",
        "\n",
        "        if filename.startswith('cat.') and filename.endswith('.jpg'):\n",
        "            class_name = 'cat'\n",
        "        elif filename.startswith('dog.') and filename.endswith('.jpg'):\n",
        "            class_name = 'dog'\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        file_path = os.path.join(base_dir, filename)\n",
        "\n",
        "        if use_color:\n",
        "            img = Image.open(file_path).convert('RGB')\n",
        "        else:\n",
        "            img = Image.open(file_path).convert('L')\n",
        "\n",
        "        img = img.resize(img_size)\n",
        "\n",
        "        if use_augmentation:\n",
        "            images_to_process = augment_image(img)\n",
        "        else:\n",
        "            images_to_process = [img]\n",
        "\n",
        "        for processed_img in images_to_process:\n",
        "            img_array = np.array(processed_img).flatten()\n",
        "            img_array = img_array / 255.0\n",
        "\n",
        "            data_X.append(img_array)\n",
        "            data_Y.append(label_map[class_name])\n",
        "\n",
        "    X = np.array(data_X)\n",
        "    Y = np.array(data_Y)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# 5. 데이터 로드 및 분할 실행\n",
        "X, Y = load_and_preprocess_data(BASE_DIR, CLASSES, IMG_SIZE,\n",
        "                                 use_color=USE_COLOR,\n",
        "                                 use_augmentation=USE_AUGMENTATION)\n",
        "\n",
        "if len(X) == 0:\n",
        "    print(\"\\n[실행 중단] 로드된 이미지 데이터가 없습니다. 경로와 파일명을 확인해 주세요.\")\n",
        "else:\n",
        "    print(f\"총 {len(X)}개의 이미지 로드 완료.\")\n",
        "    print(f\"데이터 크기 (X): {X.shape}, 레이블 크기 (Y): {Y.shape}\")\n",
        "    print(f\"학습 데이터 개수: {int(len(X)*0.8)}, 테스트 데이터 개수: {int(len(X)*0.2)}\")\n",
        "\n",
        "    # 학습 데이터와 테스트 데이터 분할\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "        X, Y,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=Y\n",
        "    )\n",
        "\n",
        "    # 특징 스케일링\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # 7. SVM 모델 학습 및 평가\n",
        "    print(\"\\n\")\n",
        "    print(\"SVM 모델 학습 및 성능 분석\")\n",
        "\n",
        "    svm_model = SVC(kernel='rbf', C=10.0, gamma='scale', random_state=42)\n",
        "    svm_model.fit(X_train_scaled, Y_train)\n",
        "    Y_pred_svm = svm_model.predict(X_test_scaled)\n",
        "\n",
        "    conf_matrix_svm = confusion_matrix(Y_test, Y_pred_svm)\n",
        "    print(\"SVM 혼동 행렬 (Confusion Matrix):\")\n",
        "    print(f\"   [Cat(0) 예측] [Dog(1) 예측]\")\n",
        "    print(f\"Cat(0) 실제: {conf_matrix_svm[0]}\")\n",
        "    print(f\"Dog(1) 실제: {conf_matrix_svm[1]}\")\n",
        "\n",
        "    print(f\"정확도 (Accuracy): {accuracy_score(Y_test, Y_pred_svm):.4f}\")\n",
        "    print(f\"정밀도 (Precision): {precision_score(Y_test, Y_pred_svm, zero_division=0):.4f}\")\n",
        "    print(f\"재현율 (Recall): {recall_score(Y_test, Y_pred_svm, zero_division=0):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(Y_test, Y_pred_svm, zero_division=0):.4f}\")"
      ]
    }
  ]
}